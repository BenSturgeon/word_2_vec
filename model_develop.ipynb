{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d26427",
   "metadata": {},
   "source": [
    "# Goals of this project\n",
    "The aim of this project was to act as a simple exploratory project to practice building a fairly fundamental tool in NLP.\n",
    "\n",
    "I learned the concepts behind the word2vec model, and while it was fairly understandable I wanted to see how it would translate to code.\n",
    "\n",
    "I also got to practice working more with the pytorch library as a result, which was a big win.\n",
    "\n",
    "The biggest challenge for me in building this was getting the vector dimensions right for matrix multiplication. Learning to respect that process and approach it slowly was valuable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5b3df08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from fastcore import *\n",
    "from nbdev.showdoc import *\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bdd0ad1",
   "metadata": {},
   "source": [
    "## Data ingestion\n",
    "Here we define some functions for reading in and cleaning the data.\n",
    "\n",
    "The primary data cleaning involves removing any characters which aren't letters as well making all those letters lowercase. \n",
    "We also remove all whitespace except for single spaces between words.\n",
    "\n",
    "We want to remove words which do not carry much semantic weight on their own, which we will call stop words. We simply filter these out of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1ad8b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def remove_non_alpha_characters(data):\n",
    "    data = data.lower()\n",
    "    # use regex to remove all non-alphanumeric characters\n",
    "    data = re.sub(r'[^a-zA-Z\\s]', '', data)\n",
    "    # use regex to remove all whitespace characters\n",
    "    data = re.sub(r'\\s+', ' ', data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    stopwords = ['a', 'an', 'the', 'and', 'or', 'but', 'if', 'then', 'else', 'when', 'at', 'from', 'by', 'on', 'off', 'for', 'in', 'out', 'over', 'to', 'into', 'with', \"\"]\n",
    "    data = [word for word in data if word not in stopwords]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "4d33ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = read_file('shakespeare.txt')\n",
    "\n",
    "data = remove_non_alpha_characters(raw_data)\n",
    "data = data.split(\" \")\n",
    "data = remove_stopwords(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c69e06b",
   "metadata": {},
   "source": [
    "Here we create our dictionary of unique words which we will use for defining our embeddings.\n",
    "\n",
    "We make this into a dictionary so that later we can refer to these values and get an index from each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f1bda534",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set(list(data))\n",
    "unique_dict = {word: i for i, word in enumerate(unique_words)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0990013b",
   "metadata": {},
   "source": [
    "### Create a train loader and dataset\n",
    "Here we create a train_loader that will randomly generate samples for us to use during training.\n",
    "\n",
    "We choose a large batch size as this task does not demand a great deal of memory and larger batches help with training speed.\n",
    "\n",
    "We define only the functions here and call them later so that all hyper parameters can be defined and run in one place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "134d5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_list_without_a_value(data, value):\n",
    "    return [x for x in data if x != value]\n",
    "\n",
    "def create_dataset(window_size, data):\n",
    "    dataset = []\n",
    "\n",
    "    for index, val in enumerate(data):\n",
    "        sub = data[max(0,index-window_size):index]\n",
    "        sub.extend(data[index+1:min(index+window_size, len(data))])\n",
    "        for target in sub:\n",
    "            dataset.append((unique_dict[val],unique_dict[target]))\n",
    "    return dataset  \n",
    "\n",
    "def create_dataloader(dataset, batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "    return train_loader\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2074e36",
   "metadata": {},
   "source": [
    "## Defining our model\n",
    "\n",
    "Here we define our skipgram model class.\n",
    "\n",
    "We take advantage of the built in pytorch module and embedding class to create our vector embeddings and handle the updating of our embedding weights.\n",
    "\n",
    "Our embeddings are essentially just matrices with dimensions matching the size of our dictionary and the embedding size we choose to represent the different features that will emerge from our data.\n",
    "\n",
    "One thing to take note of is how we initialise our weights. Currently we simply use a normal distribution with a mean of 0 and std_deviation of 0.1. It is possible there are better initialisations to use here.\n",
    "We also use sparse embeddings many many of the values will be very close to, or at 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f9401026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.u_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "        self.v_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "        self.init_emb()\n",
    "\n",
    "    def init_emb(self):\n",
    "        init_mean = 0\n",
    "        init_std = 0.1\n",
    "        self.u_embeddings.weight.data.normal_(init_mean, init_std)\n",
    "        self.v_embeddings.weight.data.normal_(init_mean, init_std)\n",
    "\n",
    "    def forward(self, pos_u, pos_v, neg_v):\n",
    "        # Precompute embeddings for pos_u and pos_v\n",
    "        emb_u = self.u_embeddings(pos_u).view(-1, 1, self.embedding_dim).squeeze()\n",
    "        emb_v = self.v_embeddings(pos_v).view(-1, self.embedding_dim).squeeze()\n",
    "\n",
    "        # Compute score for pos_u and pos_v\n",
    "        score = torch.bmm(emb_u.unsqueeze(1), emb_v.unsqueeze(2)).squeeze()\n",
    "        score = torch.sigmoid(score)\n",
    "\n",
    "        # Precompute embeddings for neg_v\n",
    "        neg_emb_v = self.v_embeddings(neg_v).view(-1, self.embedding_dim, neg_v.shape[1])\n",
    "\n",
    "        # Compute scores for neg_v\n",
    "        neg_score = torch.bmm(emb_u.unsqueeze(1), neg_emb_v).squeeze()\n",
    "        neg_score = torch.sigmoid(neg_score)\n",
    "\n",
    "        return score, neg_score\n",
    "\n",
    "\n",
    "    \n",
    "    def forward_without_negatives(self, word1, word2):\n",
    "        pos_u = torch.tensor([unique_dict[word1]])\n",
    "        pos_v = torch.tensor([unique_dict[word2]])\n",
    "        emb_u = self.u_embeddings(pos_u).view(-1, 1, self.embedding_dim).squeeze()\n",
    "        emb_v = self.v_embeddings(pos_v).view(-1, self.embedding_dim).squeeze()\n",
    "        score = torch.dot(emb_u, emb_v)\n",
    "        score = torch.sigmoid(score)\n",
    "        return score\n",
    "\n",
    "    def get_dict_embeddings(self):\n",
    "        return self.u_embeddings.weight.data.cpu().numpy()\n",
    "    \n",
    "    def get_embedding_from_word(self, word):\n",
    "        index = unique_dict[word]\n",
    "        return self.u_embeddings.weight.data[index]\n",
    "    \n",
    "    def get_embedding_from_index(self, index):\n",
    "        return self.u_embeddings.weight.data[index]\n",
    "\n",
    "    def save_embedding(self, file_name):\n",
    "        # Save embedding lookup table as pkl file\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pkl.dump(self.u_embeddings.weight.data.cpu().numpy(), f)\n",
    "    \n",
    "    def import_embeddings(self, file_name):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.u_embeddings.weight.data = torch.from_numpy(pkl.load(f)).to(torch.float32)\n",
    "            self.v_embeddings.weight.data = torch.from_numpy(pkl.load(f)).to(torch.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77db4c6e",
   "metadata": {},
   "source": [
    "## Instantiating our model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "dictionary_length = len(unique_words)\n",
    "model = SkipGramModel(dictionary_length, embedding_dim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5702ad3",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "Here we create a custom loss function which gives us a loss based on the model's error when predicting a 1 or 0 for the context word or randomly sampled words.\n",
    "\n",
    "We use a custom loss function because it allows us to add weight decay to our training and capture the specific nature of what we want the model to improve at, which in this case is relatedness of words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0f32bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_function(score, neg_score, lr, weight_decay, model):\n",
    "    pos_loss = -torch.mean(torch.log(score))\n",
    "    neg_loss = -torch.mean(torch.sum(torch.log(1 - neg_score), dim=1))\n",
    "    loss = pos_loss + neg_loss\n",
    "    # add L2 regularization term\n",
    "    l2_loss = 0\n",
    "    for param in model.parameters():\n",
    "        l2_loss += torch.sum(param**2)\n",
    "        loss += weight_decay * l2_loss\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d9d29b8",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "This is the training loop for our model.\n",
    "\n",
    "Our train loader iterator is declared every epoch and we then iterate over it according to our steps per epoch.\n",
    "\n",
    "We generate our negative samples randomly at runtime as the cost of doing so is very low.\n",
    "\n",
    "The parameters passed in for training have a massive impact on model performance. \n",
    "The length of negative samples should be somewhere between 5 and 20. Having a lower numbers means the model may stray into simply having all of its values tend to 1 which is not what we want. Thus a higher number is favoured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "324ecdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]/var/folders/xr/3pxy4p9914ld14l6mxvvknvw0000gn/T/ipykernel_73322/1547006582.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_u = torch.tensor(x)\n",
      "/var/folders/xr/3pxy4p9914ld14l6mxvvknvw0000gn/T/ipykernel_73322/1547006582.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_v = torch.tensor(y)\n",
      "100%|██████████| 300/300 [00:05<00:00, 59.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 11.096736720403035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 60.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 11.10769416809082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 61.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 11.112197904586791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 62.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 11.126311365763346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 62.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 11.120251633326212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 62.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 11.119219729105632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 62.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 11.115454371770223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 62.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 11.107603842417399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 62.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 11.105810740788778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 60.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 11.097361284891765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 61.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 11.0758145682017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 62.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 11.065972531636556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 62.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 11.070559730529785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 63.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 11.069947557449341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 61.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 11.077395655314128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SkipGramModel(\n",
       "  (u_embeddings): Embedding(30997, 100, sparse=True)\n",
       "  (v_embeddings): Embedding(30997, 100, sparse=True)\n",
       ")"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(model, train_loader, batch_size, negative_sample_length, weight_decay, learning_rate, steps_per_epoch, epochs):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    for epoch in range(epochs):\n",
    "        loss_sum = 0\n",
    "        train_loader_iter = iter(train_loader)\n",
    "        for i in tqdm(range(steps_per_epoch)):\n",
    "            x, y = next(train_loader_iter)\n",
    "            pos_u = torch.tensor(x)\n",
    "            pos_v = torch.tensor(y)\n",
    "            neg_v = torch.randint(0, dictionary_length, (batch_size, negative_sample_length))\n",
    "            optimizer.zero_grad()\n",
    "            pos_score, neg_score = model(pos_u, pos_v, neg_v)\n",
    "            loss = loss_function(pos_score, neg_score, learning_rate, weight_decay, model)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "        print(\"Epoch: {}, Loss: {}\".format(epoch, loss_sum / steps_per_epoch))\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "809e9c04",
   "metadata": {},
   "source": [
    "# Training hyperparameters\n",
    "\n",
    "The key hyperparameters we choose here are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cbe187",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "negative_sample_length = 15\n",
    "weight_decay = 0.0006\n",
    "steps_per_epoch = 300\n",
    "epochs = 30\n",
    "\n",
    "dataset = create_dataset(window_size , data) \n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "train(model, train_loader, batch_size, negative_sample_length, weight_decay, learning_rate, steps_per_epoch, epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "011b5ae7",
   "metadata": {},
   "source": [
    "# Testing\n",
    "We now go to the testing phase to see how our model is performing.\n",
    "\n",
    "### Testing functions\n",
    "The following functions primarily exist to add, subtract and compare vectors. The goal is to produce intuitive results from the comparisons of our vectors.\n",
    "\n",
    "Eg the following should have a high correlation:\n",
    "flower and rose\n",
    "man and king\n",
    "\n",
    "man and woman\n",
    "\n",
    "queen and woman\n",
    "#### The following should have a low correlation\n",
    "Flower and cart\n",
    "\n",
    "concept and dog\n",
    "\n",
    "power and table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a2d4965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_vector(vector1,vector2):\n",
    "    return get_emb(vector1) - get_emb(vector2)\n",
    "\n",
    "def add_vector(vector1,vector2):\n",
    "    return get_emb(vector1) + get_emb(vector2)\n",
    "\n",
    "def cos_sim(vector1, vector2):\n",
    "    return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "\n",
    "def cos_sim_word(word1, word2):\n",
    "    vector1 = get_emb(word1)\n",
    "    vector2 = get_emb(word2)\n",
    "    return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "\n",
    "def get_emb(word):\n",
    "    return model.get_embedding_from_word(word)\n",
    "\n",
    "def invert_dictionary(dictionary):\n",
    "    return {v: k for k, v in dictionary.items()}\n",
    "\n",
    "def get_closest_vector(vector):\n",
    "    max = 0\n",
    "    target = None\n",
    "    for key,item in unique_dict.items():\n",
    "        comparative = get_emb(key)\n",
    "        comparison = cos_sim(vector, comparative)\n",
    "        if comparison > max:\n",
    "            max = comparison\n",
    "            target = key\n",
    "\n",
    "        \n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "37b692c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.071793444 ('flower', 'rose')\n",
      "0.06013174 ('flower', 'tree')\n",
      "0.25840548 ('flower', 'dog')\n",
      "0.020282041 ('flower', 'metal')\n",
      "-0.29691505 ('flower', 'cart')\n",
      "0.15087071 ('worm', 'dog')\n",
      "0.8576787 ('king', 'queen')\n",
      "0.10934762 ('king', 'royalty')\n",
      "0.06506261 ('queen', 'royalty')\n",
      "0.89401 ('man', 'king')\n",
      "0.68327093 ('woman', 'king')\n",
      "-0.023228439 ('woman', 'boot')\n",
      "0.74027056 ('child', 'prince')\n",
      "0.53369194 ('child', 'thought')\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim_word(\"flower\", \"rose\"),(\"flower\", \"rose\"))\n",
    "print(cos_sim_word(\"flower\", \"tree\"), (\"flower\", \"tree\"))\n",
    "print(cos_sim_word(\"flower\", \"dog\"), (\"flower\", \"dog\"))\n",
    "print(cos_sim_word(\"flower\", \"metal\"), (\"flower\", \"metal\"))\n",
    "print(cos_sim_word(\"flower\", \"cart\"), (\"flower\", \"cart\"))\n",
    "print(cos_sim_word(\"worm\", \"dog\"), (\"worm\", \"dog\"))\n",
    "print(cos_sim_word(\"king\", \"queen\"), (\"king\", \"queen\"))\n",
    "print(cos_sim_word(\"king\", \"royalty\"), (\"king\", \"royalty\"))\n",
    "print(cos_sim_word(\"queen\", \"royalty\"), (\"queen\", \"royalty\"))\n",
    "print(cos_sim_word(\"man\", \"king\"), (\"man\", \"king\"))\n",
    "print(cos_sim_word(\"woman\", \"king\"), (\"woman\", \"king\"))\n",
    "print(cos_sim_word(\"woman\", \"boot\"), (\"woman\", \"boot\"))\n",
    "print(cos_sim_word(\"child\", \"prince\"), (\"child\", \"prince\"))\n",
    "print(cos_sim_word(\"child\", \"thought\"), (\"child\", \"thought\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a306e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1 = unique_dict[\"king\"]\n",
    "index2 = unique_dict[\"man\"]\n",
    "vector = subtract_vector(\"king\", \"man\")\n",
    "vector = vector+ get_emb(\"woman\")\n",
    "print(get_closest_vector(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f17a947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list common words in shakespeare\n",
    "words = [\"king\",\"queen\", \"prince\", \"princess\", \"knight\",\"skull\", \"sword\", \"rose\", \"flower\", \"tree\", \"dog\", \"metal\", \"cart\", \"worm\", \"boy\"]\n",
    "\n",
    "\n",
    "def find_most_common_words(words, n, m):\n",
    "    word_counts = {}\n",
    "    for word in words:\n",
    "        if word not in word_counts:\n",
    "            word_counts[word] = 0\n",
    "        word_counts[word] += 1\n",
    "    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_words = [word[0] for word in sorted_words]\n",
    "    return sorted_words[n:m]\n",
    "\n",
    "common_words = find_most_common_words(data, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a96cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    print(get_emb(word))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "700ad8e9",
   "metadata": {},
   "source": [
    "Save the embeddings using any filename you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8d537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"embeddings\"\n",
    "reversed_unique_dict = invert_dictionary(unique_dict)\n",
    "model.save_embedding(reversed_unique_dict, \"embeddings.emb\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a6e3c82",
   "metadata": {},
   "source": [
    "Import the embeddings if you simply wish to display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings, word2id = model.import_embeddings(\"embeddings.emb\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d2227e1",
   "metadata": {},
   "source": [
    "Here we use principal component analysis to reduce our dimensions down to 2 so we can display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8d61b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "embeddings = model.get_dict_embeddings()\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings= pca.fit_transform(embeddings)\n",
    "reduced_embeddings[unique_dict[\"king\"]]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd29d7a2",
   "metadata": {},
   "source": [
    "### Display the embeddings\n",
    "display embeddings visually using matplotlib. Each word is represented by a point in 2D space.\n",
    "The x and y coordinates of the point are the first and second dimensions of the word's embedding.\n",
    "The words are labeled by their actual word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "eaadf5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for word in words:\n",
    "  coord = reduced_embeddings[unique_dict[word]]\n",
    "  plt.scatter(coord[0], coord[1])\n",
    "  plt.annotate(word, (coord[0], coord[1]))\n",
    "\n",
    "plt.savefig('embeddings.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef204305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b6a9f868315655f86619a29ce0a043959ee2de2105a58d548d1647254ae6395"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
