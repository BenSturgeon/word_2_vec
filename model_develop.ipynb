{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b3df08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ecaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        data = f.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216c676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = read_file('shakespeare.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad8b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alpha_characters(data):\n",
    "    data = data.lower()\n",
    "    # use regex to remove all non-alphanumeric characters\n",
    "    data = re.sub(r'[^a-zA-Z\\s]', '', data)\n",
    "    # use regex to remove all whitespace characters\n",
    "    data = re.sub(r'\\s+', ' ', data)\n",
    "    return data\n",
    "\n",
    "def return_unique(data):\n",
    "    unique = set(data)\n",
    "    return list(unique)\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    stopwords = ['a', 'an', 'the', 'and', 'or', 'but', 'if', 'then', 'else', 'when', 'at', 'from', 'by', 'on', 'off', 'for', 'in', 'out', 'over', 'to', 'into', 'with', \"\"]\n",
    "    data = [word for word in data if word not in stopwords]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4d33ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_non_alpha_characters(raw_data)\n",
    "data = data.split(\" \")\n",
    "data = remove_stopwords(data)\n",
    "unique_words = return_unique(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f1bda534",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dict = {word: i for i, word in enumerate(unique_words)}\n",
    "\n",
    "def one_hot_encode(words):\n",
    "    length = len(words.keys())\n",
    "    encoded_words = {}\n",
    "    for key, value in words.items():\n",
    "        one_hot = np.zeros(length)\n",
    "        one_hot[value] = 1\n",
    "        tensor = torch.from_numpy(one_hot).to(torch.int64)\n",
    "        encoded_words[key] = tensor\n",
    "\n",
    "    return encoded_words\n",
    "\n",
    "encoded_data = one_hot_encode(unique_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "134d5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_list_without_a_value(data, value):\n",
    "    return [x for x in data if x != value]\n",
    "\n",
    "\n",
    "window_size = 5\n",
    "dataset = []\n",
    "sample_data = data\n",
    "\n",
    "for i, val in enumerate(sample_data):\n",
    "    if i > len(sample_data) - window_size:\n",
    "        break\n",
    "    sub = sample_data[i:i+window_size]\n",
    "    included = return_list_without_a_value(sub, val)\n",
    "    for target in included:\n",
    "        dataset.append((unique_dict[val],unique_dict[target]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "e9ea484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = 100\n",
    "num_epochs = int(num_epochs)\n",
    "# create a train_loader that will randomly generate examples forever\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "f9401026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.u_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "        self.v_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "        self.init_emb()\n",
    "\n",
    "    def init_emb(self):\n",
    "        init_mean = 0\n",
    "        init_std = 0.01\n",
    "        self.u_embeddings.weight.data.normal_(init_mean, init_std)\n",
    "        self.v_embeddings.weight.data.normal_(init_mean, init_std)\n",
    "\n",
    "    def forward(self, pos_u, pos_v, neg_v):\n",
    "        emb_u = self.u_embeddings(pos_u).view(-1, 1, self.embedding_dim).squeeze()\n",
    "        emb_v = self.v_embeddings(pos_v).view(-1, self.embedding_dim).squeeze()\n",
    "        score = torch.bmm(emb_u.unsqueeze(1), emb_v.unsqueeze(2)).squeeze()\n",
    "        score = torch.sigmoid(score)\n",
    "        neg_emb_v = self.v_embeddings(neg_v).view(-1, self.embedding_dim, 5)\n",
    "        neg_score = torch.bmm(emb_u.unsqueeze(1), neg_emb_v).squeeze()\n",
    "        neg_score = torch.sigmoid(neg_score)\n",
    "        return score, neg_score\n",
    "    \n",
    "    def forward_without_negatives(self, word1, word2):\n",
    "        pos_u = torch.tensor([unique_dict[word1]])\n",
    "        pos_v = torch.tensor([unique_dict[word2]])\n",
    "        emb_u = self.u_embeddings(pos_u).view(-1, 1, self.embedding_dim).squeeze()\n",
    "        emb_v = self.v_embeddings(pos_v).view(-1, self.embedding_dim).squeeze()\n",
    "        score = torch.dot(emb_u, emb_v)\n",
    "        print(score)\n",
    "        score = torch.sigmoid(score)\n",
    "        return score\n",
    "\n",
    "    def get_dict_embeddings(self):\n",
    "        return self.u_embeddings.weight.data.cpu().numpy()\n",
    "    \n",
    "    def get_embedding_from_word(self, word):\n",
    "        index = unique_dict[word]\n",
    "        return self.u_embeddings.weight.data[index]\n",
    "    \n",
    "    def get_embedding_from_index(self, index):\n",
    "        return self.u_embeddings.weight.data[index]\n",
    "\n",
    "    def save_embedding(self, id2word, file_name):\n",
    "        embedding = self.u_embeddings\n",
    "        fout = open(file_name, 'w')\n",
    "        fout.write('{} {}\\n'.format(len(id2word), self.embedding_dim))\n",
    "        for wid, w in id2word.items():\n",
    "            e = ' '.join(map(lambda x: str(x), self.get_embedding_from_index(wid)))\n",
    "            fout.write('{} {}\\n'.format(w, e))\n",
    "        fout.close()\n",
    "    \n",
    "    def import_embeddings(self, file_name):\n",
    "        fin = open(file_name, 'r')\n",
    "        n, d = map(int, fin.readline().split())\n",
    "        embedding = np.zeros((n, d))\n",
    "        word2id = {}\n",
    "        for line in fin:\n",
    "            tokens = line.rstrip().split(' ')\n",
    "            word2id[tokens[0]] = len(word2id)\n",
    "            embedding[word2id[tokens[0]]] = list(map(float, tokens[1:]))\n",
    "        return embedding, word2id\n",
    "\n",
    "def non_scalar_loss(score, neg_score, lr, weight_decay):\n",
    "    pos_loss = -torch.mean(torch.log(score))\n",
    "    neg_loss = -torch.mean(torch.sum(torch.log(1 - neg_score), dim=1))\n",
    "    loss = pos_loss + neg_loss\n",
    "    # add L2 regularization term\n",
    "    l2_loss = 0\n",
    "    for param in model.parameters():\n",
    "        l2_loss += torch.sum(param**2)\n",
    "        loss += weight_decay * l2_loss\n",
    "    return loss\n",
    "  \n",
    "embedding_dim = 100\n",
    "window_size = 5\n",
    "\n",
    "dictionary_length = len(unique_words)\n",
    "\n",
    "model = SkipGramModel(dictionary_length, embedding_dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "324ecdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])\n",
      " Step [1/31691], Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/3pxy4p9914ld14l6mxvvknvw0000gn/T/ipykernel_29788/3286197428.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_u = torch.tensor(x)\n",
      "/var/folders/xr/3pxy4p9914ld14l6mxvvknvw0000gn/T/ipykernel_29788/3286197428.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_v = torch.tensor(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step [201/31691], Loss: 3.9656\n",
      " Step [401/31691], Loss: 3.9066\n",
      " Step [601/31691], Loss: 3.9168\n",
      " Step [801/31691], Loss: 3.8866\n",
      " Step [1001/31691], Loss: 3.8495\n",
      " Step [1201/31691], Loss: 3.8535\n",
      " Step [1401/31691], Loss: 3.8360\n",
      " Step [1601/31691], Loss: 3.8172\n",
      " Step [1801/31691], Loss: 3.7985\n",
      " Step [2001/31691], Loss: 3.7926\n",
      " Step [2201/31691], Loss: 3.7729\n",
      " Step [2401/31691], Loss: 3.7498\n",
      " Step [2601/31691], Loss: 3.7572\n",
      " Step [2801/31691], Loss: 3.7612\n",
      " Step [3001/31691], Loss: 3.7570\n",
      " Step [3201/31691], Loss: 3.7431\n",
      " Step [3401/31691], Loss: 3.7309\n",
      " Step [3601/31691], Loss: 3.7389\n",
      " Step [3801/31691], Loss: 3.7358\n",
      " Step [4001/31691], Loss: 3.7384\n",
      " Step [4201/31691], Loss: 3.7208\n",
      " Step [4401/31691], Loss: 3.7360\n",
      " Step [4601/31691], Loss: 3.7398\n",
      " Step [4801/31691], Loss: 3.7408\n",
      " Step [5001/31691], Loss: 3.7096\n",
      " Step [5201/31691], Loss: 3.7482\n",
      " Step [5401/31691], Loss: 3.7312\n",
      " Step [5601/31691], Loss: 3.7534\n",
      " Step [5801/31691], Loss: 3.7474\n",
      " Step [6001/31691], Loss: 3.7360\n",
      " Step [6201/31691], Loss: 3.7350\n",
      " Step [6401/31691], Loss: 3.7490\n",
      " Step [6601/31691], Loss: 3.7542\n",
      " Step [6801/31691], Loss: 3.7513\n",
      " Step [7001/31691], Loss: 3.7360\n",
      " Step [7201/31691], Loss: 3.7463\n",
      " Step [7401/31691], Loss: 3.7377\n",
      " Step [7601/31691], Loss: 3.7541\n",
      " Step [7801/31691], Loss: 3.7576\n",
      " Step [8001/31691], Loss: 3.7409\n",
      " Step [8201/31691], Loss: 3.7352\n",
      " Step [8401/31691], Loss: 3.7569\n",
      " Step [8601/31691], Loss: 3.7647\n",
      " Step [8801/31691], Loss: 3.7495\n",
      " Step [9001/31691], Loss: 3.7480\n",
      " Step [9201/31691], Loss: 3.7338\n",
      " Step [9401/31691], Loss: 3.7553\n",
      " Step [9601/31691], Loss: 3.7647\n",
      " Step [9801/31691], Loss: 3.7440\n",
      " Step [10001/31691], Loss: 3.7535\n",
      " Step [10201/31691], Loss: 3.7491\n",
      " Step [10401/31691], Loss: 3.7365\n",
      " Step [10601/31691], Loss: 3.7512\n",
      " Step [10801/31691], Loss: 3.7555\n",
      " Step [11001/31691], Loss: 3.7468\n",
      " Step [11201/31691], Loss: 3.7376\n",
      " Step [11401/31691], Loss: 3.7475\n",
      " Step [11601/31691], Loss: 3.7577\n",
      " Step [11801/31691], Loss: 3.7330\n",
      " Step [12001/31691], Loss: 3.7521\n",
      " Step [12201/31691], Loss: 3.7466\n",
      " Step [12401/31691], Loss: 3.7599\n",
      " Step [12601/31691], Loss: 3.7275\n",
      " Step [12801/31691], Loss: 3.7421\n",
      " Step [13001/31691], Loss: 3.7407\n",
      " Step [13201/31691], Loss: 3.7404\n",
      " Step [13401/31691], Loss: 3.7452\n",
      " Step [13601/31691], Loss: 3.7524\n",
      " Step [13801/31691], Loss: 3.7331\n",
      " Step [14001/31691], Loss: 3.7680\n",
      " Step [14201/31691], Loss: 3.7450\n",
      " Step [14401/31691], Loss: 3.7343\n",
      " Step [14601/31691], Loss: 3.7360\n",
      " Step [14801/31691], Loss: 3.7380\n",
      " Step [15001/31691], Loss: 3.7492\n",
      " Step [15201/31691], Loss: 3.7364\n",
      " Step [15401/31691], Loss: 3.7499\n",
      " Step [15601/31691], Loss: 3.7445\n",
      " Step [15801/31691], Loss: 3.7485\n",
      " Step [16001/31691], Loss: 3.7385\n",
      " Step [16201/31691], Loss: 3.7346\n",
      " Step [16401/31691], Loss: 3.7326\n",
      " Step [16601/31691], Loss: 3.7463\n",
      " Step [16801/31691], Loss: 3.7341\n",
      " Step [17001/31691], Loss: 3.7301\n",
      " Step [17201/31691], Loss: 3.7353\n",
      " Step [17401/31691], Loss: 3.7235\n",
      " Step [17601/31691], Loss: 3.7482\n",
      " Step [17801/31691], Loss: 3.7407\n",
      " Step [18001/31691], Loss: 3.7488\n",
      " Step [18201/31691], Loss: 3.7470\n",
      " Step [18401/31691], Loss: 3.7317\n",
      " Step [18601/31691], Loss: 3.7307\n",
      " Step [18801/31691], Loss: 3.7484\n",
      " Step [19001/31691], Loss: 3.7473\n",
      " Step [19201/31691], Loss: 3.7486\n",
      " Step [19401/31691], Loss: 3.7285\n",
      " Step [19601/31691], Loss: 3.7353\n",
      " Step [19801/31691], Loss: 3.7460\n",
      " Step [20001/31691], Loss: 3.7238\n",
      " Step [20201/31691], Loss: 3.7204\n",
      " Step [20401/31691], Loss: 3.7146\n",
      " Step [20601/31691], Loss: 3.7116\n",
      " Step [20801/31691], Loss: 3.7271\n",
      " Step [21001/31691], Loss: 3.7336\n",
      " Step [21201/31691], Loss: 3.7323\n",
      " Step [21401/31691], Loss: 3.7100\n",
      " Step [21601/31691], Loss: 3.7289\n",
      " Step [21801/31691], Loss: 3.7271\n",
      " Step [22001/31691], Loss: 3.7203\n",
      " Step [22201/31691], Loss: 3.7407\n",
      " Step [22401/31691], Loss: 3.7390\n",
      " Step [22601/31691], Loss: 3.7230\n",
      " Step [22801/31691], Loss: 3.7228\n",
      " Step [23001/31691], Loss: 3.7254\n",
      " Step [23201/31691], Loss: 3.7131\n",
      " Step [23401/31691], Loss: 3.7169\n",
      " Step [23601/31691], Loss: 3.7247\n",
      " Step [23801/31691], Loss: 3.7210\n",
      " Step [24001/31691], Loss: 3.7149\n",
      " Step [24201/31691], Loss: 3.7307\n",
      " Step [24401/31691], Loss: 3.7253\n",
      " Step [24601/31691], Loss: 3.7311\n",
      " Step [24801/31691], Loss: 3.7254\n",
      " Step [25001/31691], Loss: 3.7182\n",
      " Step [25201/31691], Loss: 3.7278\n",
      " Step [25401/31691], Loss: 3.7169\n",
      " Step [25601/31691], Loss: 3.7309\n",
      " Step [25801/31691], Loss: 3.7251\n",
      " Step [26001/31691], Loss: 3.7069\n",
      " Step [26201/31691], Loss: 3.7262\n",
      " Step [26401/31691], Loss: 3.7019\n",
      " Step [26601/31691], Loss: 3.7004\n",
      " Step [26801/31691], Loss: 3.7114\n",
      " Step [27001/31691], Loss: 3.7095\n",
      " Step [27201/31691], Loss: 3.7269\n",
      " Step [27401/31691], Loss: 3.7126\n",
      " Step [27601/31691], Loss: 3.7260\n",
      " Step [27801/31691], Loss: 3.7225\n",
      " Step [28001/31691], Loss: 3.7241\n",
      " Step [28201/31691], Loss: 3.7069\n",
      " Step [28401/31691], Loss: 3.7182\n",
      " Step [28601/31691], Loss: 3.7137\n",
      " Step [28801/31691], Loss: 3.7101\n",
      " Step [29001/31691], Loss: 3.7218\n",
      " Step [29201/31691], Loss: 3.7057\n",
      " Step [29401/31691], Loss: 3.7157\n",
      " Step [29601/31691], Loss: 3.7193\n",
      " Step [29801/31691], Loss: 3.7052\n",
      " Step [30001/31691], Loss: 3.7082\n",
      " Step [30201/31691], Loss: 3.6933\n",
      " Step [30401/31691], Loss: 3.7225\n",
      " Step [30601/31691], Loss: 3.6995\n",
      " Step [30801/31691], Loss: 3.7022\n",
      " Step [31001/31691], Loss: 3.7048\n",
      " Step [31201/31691], Loss: 3.7140\n",
      " Step [31401/31691], Loss: 3.7193\n",
      " Step [1/31691], Loss: 3.6003\n",
      " Step [201/31691], Loss: 3.7068\n",
      " Step [401/31691], Loss: 3.7291\n",
      " Step [601/31691], Loss: 3.7097\n",
      " Step [801/31691], Loss: 3.7134\n",
      " Step [1001/31691], Loss: 3.6974\n",
      " Step [1201/31691], Loss: 3.7157\n",
      " Step [1401/31691], Loss: 3.6974\n",
      " Step [1601/31691], Loss: 3.7118\n",
      " Step [1801/31691], Loss: 3.7179\n",
      " Step [2001/31691], Loss: 3.7121\n",
      " Step [2201/31691], Loss: 3.6977\n",
      " Step [2401/31691], Loss: 3.7175\n",
      " Step [2601/31691], Loss: 3.7081\n",
      " Step [2801/31691], Loss: 3.7056\n",
      " Step [3001/31691], Loss: 3.7041\n",
      " Step [3201/31691], Loss: 3.6978\n",
      " Step [3401/31691], Loss: 3.7159\n",
      " Step [3601/31691], Loss: 3.7139\n",
      " Step [3801/31691], Loss: 3.6965\n",
      " Step [4001/31691], Loss: 3.7188\n",
      " Step [4201/31691], Loss: 3.7131\n",
      " Step [4401/31691], Loss: 3.6953\n",
      " Step [4601/31691], Loss: 3.7032\n",
      " Step [4801/31691], Loss: 3.7187\n",
      " Step [5001/31691], Loss: 3.7215\n",
      " Step [5201/31691], Loss: 3.7050\n",
      " Step [5401/31691], Loss: 3.7142\n",
      " Step [5601/31691], Loss: 3.7145\n",
      " Step [5801/31691], Loss: 3.7117\n",
      " Step [6001/31691], Loss: 3.7326\n",
      " Step [6201/31691], Loss: 3.7166\n",
      " Step [6401/31691], Loss: 3.7116\n",
      " Step [6601/31691], Loss: 3.7069\n",
      " Step [6801/31691], Loss: 3.7129\n",
      " Step [7001/31691], Loss: 3.7199\n",
      " Step [7201/31691], Loss: 3.7162\n",
      " Step [7401/31691], Loss: 3.6996\n",
      " Step [7601/31691], Loss: 3.7045\n",
      " Step [7801/31691], Loss: 3.7046\n",
      " Step [8001/31691], Loss: 3.7077\n",
      " Step [8201/31691], Loss: 3.7070\n",
      " Step [8401/31691], Loss: 3.7117\n",
      " Step [8601/31691], Loss: 3.7268\n",
      " Step [8801/31691], Loss: 3.7047\n",
      " Step [9001/31691], Loss: 3.7123\n",
      " Step [9201/31691], Loss: 3.7062\n",
      " Step [9401/31691], Loss: 3.7044\n",
      " Step [9601/31691], Loss: 3.7048\n",
      " Step [9801/31691], Loss: 3.7073\n",
      " Step [10001/31691], Loss: 3.7100\n",
      " Step [10201/31691], Loss: 3.6979\n",
      " Step [10401/31691], Loss: 3.7178\n",
      " Step [10601/31691], Loss: 3.7094\n",
      " Step [10801/31691], Loss: 3.7150\n",
      " Step [11001/31691], Loss: 3.6995\n",
      " Step [11201/31691], Loss: 3.7185\n",
      " Step [11401/31691], Loss: 3.7009\n",
      " Step [11601/31691], Loss: 3.7068\n",
      " Step [11801/31691], Loss: 3.7170\n",
      " Step [12001/31691], Loss: 3.7040\n",
      " Step [12201/31691], Loss: 3.7229\n",
      " Step [12401/31691], Loss: 3.7145\n",
      " Step [12601/31691], Loss: 3.7282\n",
      " Step [12801/31691], Loss: 3.7048\n",
      " Step [13001/31691], Loss: 3.7019\n",
      " Step [13201/31691], Loss: 3.7156\n",
      " Step [13401/31691], Loss: 3.7059\n",
      " Step [13601/31691], Loss: 3.7092\n",
      " Step [13801/31691], Loss: 3.7046\n",
      " Step [14001/31691], Loss: 3.6918\n",
      " Step [14201/31691], Loss: 3.6927\n",
      " Step [14401/31691], Loss: 3.6990\n",
      " Step [14601/31691], Loss: 3.6868\n",
      " Step [14801/31691], Loss: 3.7209\n",
      " Step [15001/31691], Loss: 3.7146\n",
      " Step [15201/31691], Loss: 3.7145\n",
      " Step [15401/31691], Loss: 3.7106\n",
      " Step [15601/31691], Loss: 3.7140\n",
      " Step [15801/31691], Loss: 3.7204\n",
      " Step [16001/31691], Loss: 3.7188\n",
      " Step [16201/31691], Loss: 3.7100\n",
      " Step [16401/31691], Loss: 3.7145\n",
      " Step [16601/31691], Loss: 3.7006\n",
      " Step [16801/31691], Loss: 3.7112\n",
      " Step [17001/31691], Loss: 3.7119\n",
      " Step [17201/31691], Loss: 3.6955\n",
      " Step [17401/31691], Loss: 3.7075\n",
      " Step [17601/31691], Loss: 3.7049\n",
      " Step [17801/31691], Loss: 3.7090\n",
      " Step [18001/31691], Loss: 3.7057\n",
      " Step [18201/31691], Loss: 3.7045\n",
      " Step [18401/31691], Loss: 3.7117\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [434], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m loss \u001b[39m=\u001b[39mnon_scalar_loss(pos_score, neg_score, learning_rate, \u001b[39m0.0001\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[39m# loss = criterion(score, concat_data)\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     35\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     36\u001b[0m loss_sum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/werk/word_2_vec/venv_wordvec/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/werk/word_2_vec/venv_wordvec/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.BCELoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "# optimizer = torch.optim.SparseAdam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_sum = 0\n",
    "\n",
    "negative_sample_length = 5\n",
    "\n",
    "pos_u_data = torch.ones(batch_size)\n",
    "neg_v_data = torch.zeros(batch_size*negative_sample_length)\n",
    "concat_data = torch.cat([pos_u_data, neg_v_data], dim=0)\n",
    "print(concat_data)\n",
    "step_interval = 200\n",
    "\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        pos_u = torch.tensor(x)\n",
    "        pos_v = torch.tensor(y)\n",
    "        neg_v = torch.randint(0, dictionary_length, (batch_size, negative_sample_length))\n",
    "        # print(neg_v.shape)\n",
    "        optimizer.zero_grad()\n",
    "        pos_score, neg_score = model(pos_u, pos_v, neg_v)\n",
    "        # score = torch.cat([pos_score, neg_score.flatten()], dim=0)\n",
    "        # combined_len = len(pos_score) + len(neg_score)\n",
    "        # # add a column of ones to pos_u_data\n",
    "        # pos_u_data = torch.ones(len(pos_u), 1)\n",
    "        # neg_v_data = torch.zeros(len(neg_score.flatten()), 1)\n",
    "        # print(score.shape, concat_data.shape)\n",
    "        loss =non_scalar_loss(pos_score, neg_score, learning_rate, 0.0001)\n",
    "        # loss = criterion(score, concat_data)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "        if i % step_interval == 0:\n",
    "            print(' Step [{}/{}], Loss: {:.4f}' \n",
    "                    .format(i+1, len(dataset)//batch_size, loss_sum/step_interval))\n",
    "            loss_sum = 0\n",
    "        if i > len(train_loader) - batch_size:\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5bcb76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d4965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_vector(vector1,vector2):\n",
    "    return get_emb(vector1) - get_emb(vector2)\n",
    "\n",
    "def add_vector(vector1,vector2):\n",
    "    return get_emb(vector1) + get_emb(vector2)\n",
    "\n",
    "def cos_sim(vector1, vector2):\n",
    "    return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "\n",
    "def cos_sim_word(word1, word2):\n",
    "    vector1 = get_emb(word1)\n",
    "    vector2 = get_emb(word2)\n",
    "    return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "\n",
    "def get_emb(word):\n",
    "    return model.get_embedding_from_word(word)\n",
    "\n",
    "def invert_dictionary(dictionary):\n",
    "    return {v: k for k, v in dictionary.items()}\n",
    "\n",
    "def get_closest_vector(vector):\n",
    "    max = 0\n",
    "    target = None\n",
    "    for key,item in unique_dict.items():\n",
    "        comparative = get_emb(key)\n",
    "        comparison = cos_sim(vector, comparative)\n",
    "        if comparison > max:\n",
    "            max = comparison\n",
    "            target = key\n",
    "\n",
    "        \n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "e70f99ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = subtract_vector(\"king\", \"man\")\n",
    "vector = vector +get_emb(\"woman\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "37b692c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7398989 ('flower', 'rose')\n",
      "0.7130939 ('flower', 'tree')\n",
      "0.71860266 ('flower', 'dog')\n",
      "0.27536592 ('flower', 'cat')\n",
      "0.38623956 ('flower', 'car')\n",
      "0.29542333 ('cat', 'dog')\n",
      "0.9707984 ('king', 'queen')\n",
      "0.66462225 ('king', 'royalty')\n",
      "0.6328036 ('queen', 'royalty')\n",
      "0.9732659 ('man', 'king')\n",
      "0.9547602 ('woman', 'king')\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim_word(\"flower\", \"rose\"),(\"flower\", \"rose\"))\n",
    "print(cos_sim_word(\"flower\", \"tree\"), (\"flower\", \"tree\"))\n",
    "print(cos_sim_word(\"flower\", \"dog\"), (\"flower\", \"dog\"))\n",
    "print(cos_sim_word(\"flower\", \"cat\"), (\"flower\", \"cat\"))\n",
    "print(cos_sim_word(\"flower\", \"car\"), (\"flower\", \"car\"))\n",
    "print(cos_sim_word(\"cat\", \"dog\"), (\"cat\", \"dog\"))\n",
    "print(cos_sim_word(\"king\", \"queen\"), (\"king\", \"queen\"))\n",
    "print(cos_sim_word(\"king\", \"royalty\"), (\"king\", \"royalty\"))\n",
    "print(cos_sim_word(\"queen\", \"royalty\"), (\"queen\", \"royalty\"))\n",
    "print(cos_sim_word(\"man\", \"king\"), (\"man\", \"king\"))\n",
    "print(cos_sim_word(\"woman\", \"king\"), (\"woman\", \"king\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "0fc74988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5397, grad_fn=<DotBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9718, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed_unique_dict = invert_dictionary(unique_dict)\n",
    "model.forward_without_negatives(\"king\", \"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "a306e7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/3pxy4p9914ld14l6mxvvknvw0000gn/T/ipykernel_29788/1849800357.py:8: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cacodemon\n"
     ]
    }
   ],
   "source": [
    "index1 = unique_dict[\"king\"]\n",
    "index2 = unique_dict[\"man\"]\n",
    "vector = subtract_vector(\"king\", \"man\")\n",
    "vector = vector+ get_emb(\"woman\")\n",
    "print(get_closest_vector(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "3d8d537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embeddings\n",
    "path = \"embeddings\"\n",
    "model.save_embedding\n",
    "model.save_embedding(reversed_unique_dict, \"embeddings.emb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "86a168ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (1035514023.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [441], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(model.u_embeddings.mean()))\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "print(model.u_embeddings.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaadf5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b6a9f868315655f86619a29ce0a043959ee2de2105a58d548d1647254ae6395"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
