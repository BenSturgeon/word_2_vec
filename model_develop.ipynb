{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d26427",
   "metadata": {},
   "source": [
    "# Goals of this project\n",
    "The aim of this project was to act as a simple exploratory project to practice building a fairly fundamental tool in NLP.\n",
    "\n",
    "I learned the concepts behind the word2vec model, and while it was fairly understandable I wanted to see how it would translate to code.\n",
    "\n",
    "I also got to practice working more with the pytorch library as a result, which was a big win.\n",
    "\n",
    "The biggest challenge for me in building this was getting the vector dimensions right for matrix multiplication. Learning to respect that process and approach it slowly was valuable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b3df08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from fastcore import *\n",
    "from nbdev.showdoc import *\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ecaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        data = f.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "216c676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = read_file('shakespeare.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad8b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alpha_characters(data):\n",
    "    data = data.lower()\n",
    "    # use regex to remove all non-alphanumeric characters\n",
    "    data = re.sub(r'[^a-zA-Z\\s]', '', data)\n",
    "    # use regex to remove all whitespace characters\n",
    "    data = re.sub(r'\\s+', ' ', data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    stopwords = ['a', 'an', 'the', 'and', 'or', 'but', 'if', 'then', 'else', 'when', 'at', 'from', 'by', 'on', 'off', 'for', 'in', 'out', 'over', 'to', 'into', 'with', \"\"]\n",
    "    data = [word for word in data if word not in stopwords]\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_encode(words):\n",
    "    length = len(words.keys())\n",
    "    encoded_words = {}\n",
    "    for key, value in words.items():\n",
    "        one_hot = np.zeros(length)\n",
    "        one_hot[value] = 1\n",
    "        tensor = torch.from_numpy(one_hot).to(torch.int64)\n",
    "        encoded_words[key] = tensor\n",
    "\n",
    "    return encoded_words\n",
    "\n",
    "\n",
    "\n",
    "def get_scalar_loss(pos_score, neg_score, criterion, concatenated_data):\n",
    "    \"\"\"function to get the scalar loss. Unused because the results are generally bad from my current experiments.\"\"\"\n",
    "    score = torch.cat([pos_score, neg_score.flatten()], dim=0)\n",
    "    combined_len = len(pos_score) + len(neg_score)\n",
    "    pos_u_data = torch.ones(len(pos_score), 1)\n",
    "    neg_v_data = torch.zeros(len(neg_score.flatten()), 1)\n",
    "    loss = criterion(score, concatenated_data)\n",
    "    return loss\n",
    "    loss = get_scalar_loss( pos_score, neg_score, criterion, concat_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d33ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_non_alpha_characters(raw_data)\n",
    "data = data.split(\" \")\n",
    "data = remove_stopwords(data)\n",
    "unique_words = set(list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1bda534",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dict = {word: i for i, word in enumerate(unique_words)}\n",
    "\n",
    "\n",
    "encoded_data = one_hot_encode(unique_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0990013b",
   "metadata": {},
   "source": [
    "### Create a train loader and dataset\n",
    "Here we create a train_loader that will randomly generate examples forever\n",
    "\n",
    "We choose a large batch size as this task does not demand a great deal of RAM and larger batches help with training speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "134d5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_list_without_a_value(data, value):\n",
    "    return [x for x in data if x != value]\n",
    "\n",
    "def create_dataset(window_size, data):\n",
    "    dataset = []\n",
    "\n",
    "    for index, val in enumerate(data):\n",
    "        sub = data[max(0,index-window_size):index]\n",
    "        sub.extend(data[index+1:min(index+window_size, len(data))])\n",
    "        for target in sub:\n",
    "            dataset.append((unique_dict[val],unique_dict[target]))\n",
    "    return dataset  \n",
    "\n",
    "window_size = 8\n",
    "dataset = create_dataset(window_size , data) \n",
    "\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9401026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.u_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "        self.v_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "        self.init_emb()\n",
    "\n",
    "    def init_emb(self):\n",
    "        init_mean = 0\n",
    "        init_std = 0.01\n",
    "        self.u_embeddings.weight.data.normal_(init_mean, init_std)\n",
    "        self.v_embeddings.weight.data.normal_(init_mean, init_std)\n",
    "\n",
    "    def forward(self, pos_u, pos_v, neg_v):\n",
    "        # Precompute embeddings for pos_u and pos_v\n",
    "        emb_u = self.u_embeddings(pos_u).view(-1, 1, self.embedding_dim).squeeze()\n",
    "        emb_v = self.v_embeddings(pos_v).view(-1, self.embedding_dim).squeeze()\n",
    "\n",
    "        # Compute score for pos_u and pos_v\n",
    "        score = torch.bmm(emb_u.unsqueeze(1), emb_v.unsqueeze(2)).squeeze()\n",
    "        score = torch.sigmoid(score)\n",
    "\n",
    "        # Precompute embeddings for neg_v\n",
    "        neg_emb_v = self.v_embeddings(neg_v).view(-1, self.embedding_dim, neg_v.shape[1])\n",
    "\n",
    "        # Compute scores for neg_v\n",
    "        neg_score = torch.bmm(emb_u.unsqueeze(1), neg_emb_v).squeeze()\n",
    "        neg_score = torch.sigmoid(neg_score)\n",
    "\n",
    "        return score, neg_score\n",
    "\n",
    "\n",
    "    \n",
    "    def forward_without_negatives(self, word1, word2):\n",
    "        pos_u = torch.tensor([unique_dict[word1]])\n",
    "        pos_v = torch.tensor([unique_dict[word2]])\n",
    "        emb_u = self.u_embeddings(pos_u).view(-1, 1, self.embedding_dim).squeeze()\n",
    "        emb_v = self.v_embeddings(pos_v).view(-1, self.embedding_dim).squeeze()\n",
    "        score = torch.dot(emb_u, emb_v)\n",
    "        score = torch.sigmoid(score)\n",
    "        return score\n",
    "\n",
    "    def get_dict_embeddings(self):\n",
    "        return self.u_embeddings.weight.data.cpu().numpy()\n",
    "    \n",
    "    def get_embedding_from_word(self, word):\n",
    "        index = unique_dict[word]\n",
    "        return self.u_embeddings.weight.data[index]\n",
    "    \n",
    "    def get_embedding_from_index(self, index):\n",
    "        return self.u_embeddings.weight.data[index]\n",
    "\n",
    "    def save_embedding(self, file_name):\n",
    "        # Save embedding lookup table as pkl file\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pkl.dump(self.u_embeddings.weight.data.cpu().numpy(), f)\n",
    "    \n",
    "    def import_embeddings(self, file_name):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.u_embeddings.weight.data = torch.from_numpy(pkl.load(f)).to(torch.float32)\n",
    "            self.v_embeddings.weight.data = torch.from_numpy(pkl.load(f)).to(torch.float32)\n",
    "\n",
    "  \n",
    "embedding_dim = 100\n",
    "dictionary_length = len(unique_words)\n",
    "model = SkipGramModel(dictionary_length, embedding_dim)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5702ad3",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "Here we create a custom loss function which gives us a loss based on the model's error when predicting a 1 or 0 for the context word or randomly sampled words.\n",
    "\n",
    "We use a custom loss function because it allows us to add weight decay to our training and capture the specific nature of what we want the model to improve at, which in this case is relatedness of words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f32bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_function(score, neg_score, lr, weight_decay, model):\n",
    "    pos_loss = -torch.mean(torch.log(score))\n",
    "    neg_loss = -torch.mean(torch.sum(torch.log(1 - neg_score), dim=1))\n",
    "    loss = pos_loss + neg_loss\n",
    "    # add L2 regularization term\n",
    "    l2_loss = 0\n",
    "    for param in model.parameters():\n",
    "        l2_loss += torch.sum(param**2)\n",
    "        loss += weight_decay * l2_loss\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d9d29b8",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "This is the training loop for our model.\n",
    "\n",
    "Our train loader iterator is declared every epoch and we then iterate over it according to our steps per epoch.\n",
    "\n",
    "We generate our negative samples randomly at runtime as the cost of doing so is very low.\n",
    "\n",
    "The parameters passed in for training have a massive impact on model performance. \n",
    "The length of negative samples should be somewhere between 5 and 20. Having a lower numbers means the model may stray into simply having all of its values tend to 1 which is not what we want. Thus a higher number is favoured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "324ecdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]/var/folders/xr/3pxy4p9914ld14l6mxvvknvw0000gn/T/ipykernel_72349/1547006582.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_u = torch.tensor(x)\n",
      "/var/folders/xr/3pxy4p9914ld14l6mxvvknvw0000gn/T/ipykernel_72349/1547006582.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_v = torch.tensor(y)\n",
      "100%|██████████| 300/300 [00:05<00:00, 59.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 11.1058136622111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:05<00:00, 58.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 11.077984917958577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 71/300 [00:01<00:03, 61.46it/s]"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, batch_size, negative_sample_length, weight_decay, learning_rate, steps_per_epoch, epochs):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    for epoch in range(epochs):\n",
    "        loss_sum = 0\n",
    "        train_loader_iter = iter(train_loader)\n",
    "        for i in tqdm(range(steps_per_epoch)):\n",
    "            x, y = next(train_loader_iter)\n",
    "            pos_u = torch.tensor(x)\n",
    "            pos_v = torch.tensor(y)\n",
    "            neg_v = torch.randint(0, dictionary_length, (batch_size, negative_sample_length))\n",
    "            optimizer.zero_grad()\n",
    "            pos_score, neg_score = model(pos_u, pos_v, neg_v)\n",
    "            loss = loss_function(pos_score, neg_score, learning_rate, weight_decay, model)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "        print(\"Epoch: {}, Loss: {}\".format(epoch, loss_sum / steps_per_epoch))\n",
    "    return model\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "negative_sample_length = 15\n",
    "weight_decay = 0.0006\n",
    "\n",
    "steps_per_epoch = 300\n",
    "epochs = 15\n",
    "\n",
    "train(model, train_loader, batch_size, negative_sample_length, weight_decay, learning_rate, steps_per_epoch, epochs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "011b5ae7",
   "metadata": {},
   "source": [
    "# Testing\n",
    "We now go to the testing phase to see how our model is performing.\n",
    "\n",
    "### Testing functions\n",
    "The following functions primarily exist to add, subtract and compare vectors. The goal is to produce intuitive results from the comparisons of our vectors.\n",
    "\n",
    "Eg the following should have a high correlation:\n",
    "flower and rose\n",
    "man and king\n",
    "\n",
    "man and woman\n",
    "\n",
    "queen and woman\n",
    "#### The following should have a low correlation\n",
    "Flower and metal\n",
    "\n",
    "concept and dog\n",
    "\n",
    "power and table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2d4965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_vector(vector1,vector2):\n",
    "    return get_emb(vector1) - get_emb(vector2)\n",
    "\n",
    "def add_vector(vector1,vector2):\n",
    "    return get_emb(vector1) + get_emb(vector2)\n",
    "\n",
    "def cos_sim(vector1, vector2):\n",
    "    return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "\n",
    "def cos_sim_word(word1, word2):\n",
    "    vector1 = get_emb(word1)\n",
    "    vector2 = get_emb(word2)\n",
    "    return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "\n",
    "def get_emb(word):\n",
    "    return model.get_embedding_from_word(word)\n",
    "\n",
    "def invert_dictionary(dictionary):\n",
    "    return {v: k for k, v in dictionary.items()}\n",
    "\n",
    "def get_closest_vector(vector):\n",
    "    max = 0\n",
    "    target = None\n",
    "    for key,item in unique_dict.items():\n",
    "        comparative = get_emb(key)\n",
    "        comparison = cos_sim(vector, comparative)\n",
    "        if comparison > max:\n",
    "            max = comparison\n",
    "            target = key\n",
    "\n",
    "        \n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e70f99ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = subtract_vector(\"king\", \"man\")\n",
    "vector = vector +get_emb(\"woman\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37b692c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8538131 ('flower', 'rose')\n",
      "0.68368065 ('flower', 'tree')\n",
      "0.9014465 ('flower', 'dog')\n",
      "-0.16055314 ('flower', 'metal')\n",
      "0.065594286 ('flower', 'cart')\n",
      "0.8298176 ('worm', 'dog')\n",
      "0.99682665 ('king', 'queen')\n",
      "0.9448121 ('king', 'royalty')\n",
      "0.93152064 ('queen', 'royalty')\n",
      "0.9976486 ('man', 'king')\n",
      "0.9650337 ('woman', 'king')\n",
      "0.64117473 ('woman', 'boot')\n",
      "0.9606477 ('child', 'prince')\n",
      "0.9548535 ('child', 'thought')\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim_word(\"flower\", \"rose\"),(\"flower\", \"rose\"))\n",
    "print(cos_sim_word(\"flower\", \"tree\"), (\"flower\", \"tree\"))\n",
    "print(cos_sim_word(\"flower\", \"dog\"), (\"flower\", \"dog\"))\n",
    "print(cos_sim_word(\"flower\", \"metal\"), (\"flower\", \"metal\"))\n",
    "print(cos_sim_word(\"flower\", \"cart\"), (\"flower\", \"cart\"))\n",
    "print(cos_sim_word(\"worm\", \"dog\"), (\"worm\", \"dog\"))\n",
    "print(cos_sim_word(\"king\", \"queen\"), (\"king\", \"queen\"))\n",
    "print(cos_sim_word(\"king\", \"royalty\"), (\"king\", \"royalty\"))\n",
    "print(cos_sim_word(\"queen\", \"royalty\"), (\"queen\", \"royalty\"))\n",
    "print(cos_sim_word(\"man\", \"king\"), (\"man\", \"king\"))\n",
    "print(cos_sim_word(\"woman\", \"king\"), (\"woman\", \"king\"))\n",
    "print(cos_sim_word(\"woman\", \"boot\"), (\"woman\", \"boot\"))\n",
    "print(cos_sim_word(\"child\", \"prince\"), (\"child\", \"prince\"))\n",
    "print(cos_sim_word(\"child\", \"thought\"), (\"child\", \"thought\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fc74988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5974, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward_without_negatives(\"king\", \"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a306e7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/3pxy4p9914ld14l6mxvvknvw0000gn/T/ipykernel_72349/1849800357.py:8: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fortnight\n"
     ]
    }
   ],
   "source": [
    "index1 = unique_dict[\"king\"]\n",
    "index2 = unique_dict[\"man\"]\n",
    "vector = subtract_vector(\"king\", \"man\")\n",
    "vector = vector+ get_emb(\"woman\")\n",
    "print(get_closest_vector(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d8d537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embeddings\n",
    "path = \"embeddings\"\n",
    "reversed_unique_dict = invert_dictionary(unique_dict)\n",
    "model.save_embedding(reversed_unique_dict, \"embeddings.emb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eaadf5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display embeddings visually using matplotlib. Each word is represented by a point in 2D space.\n",
    "# The x and y coordinates of the point are the first and second dimensions of the word's embedding.\n",
    "# The words are labeled by their actual word.\n",
    "import matplotlib as plt\n",
    "\n",
    "def display_embeddings(embeddings, word2id, filename):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i, label in enumerate(word2id):\n",
    "        x, y = embeddings[i, :]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')\n",
    "    plt.savefig(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69bb28aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'tensor(0.0014)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings, word2id \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mimport_embeddings(\u001b[39m\"\u001b[39;49m\u001b[39membeddings.emb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m display_embeddings(embeddings, word2id, \u001b[39m\"\u001b[39m\u001b[39membeddings.png\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [35], line 76\u001b[0m, in \u001b[0;36mSkipGramModel.import_embeddings\u001b[0;34m(self, file_name)\u001b[0m\n\u001b[1;32m     74\u001b[0m     tokens \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39mrstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     75\u001b[0m     word2id[tokens[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m i\n\u001b[0;32m---> 76\u001b[0m     embeddings[i] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(\u001b[39mfloat\u001b[39;49m, tokens[\u001b[39m1\u001b[39;49m:]))\n\u001b[1;32m     77\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings, word2id\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'tensor(0.0014)'"
     ]
    }
   ],
   "source": [
    "embeddings, word2id = model.import_embeddings(\"embeddings.emb\")\n",
    "display_embeddings(embeddings, word2id, \"embeddings.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9eed812b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'convert_to_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mconvert_to_tensor(\u001b[39m'\u001b[39m\u001b[39mtensor(0.0014)\u001b[39m\u001b[39m'\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat64)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'convert_to_tensor'"
     ]
    }
   ],
   "source": [
    "torch.convert_to_tensor('tensor(0.0014)', dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcf2d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = torch.tensor(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99d2d8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3bdfac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b6a9f868315655f86619a29ce0a043959ee2de2105a58d548d1647254ae6395"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
